{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de398d93",
   "metadata": {},
   "source": [
    "## 토픽 모델링 (Topic Modeling) - 20newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94351849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "#20가지 주제의 뉴스 그룹에서 8개 주제를 추출하고 이들 텍스트에 LDA 기반의 토픽 모델링 적용\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "#위에서 cats 변수로 기재된 카테고리만 추출\n",
    "news_df = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=cats, random_state=0)\n",
    "\n",
    "#LDA는 Count 기반의 벡터화만 적용\n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1, 2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb3130c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdb93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit() 적용하면 components_ 속성 가지게 됨, 개별 토픽별로 각 word 피처가 얼마나 많이 그 토픽에 할당 되었는지에 대한 수치 가짐\n",
    "#8개의 토픽별로 1000개의 word 피처가 해당 토필별로 연관도 값 가지고 있음\n",
    "#즉, components_ array[0, 10]은 Topic #0에 대해서 피처 벡터화된 행렬에서 10번째 칼럼에 있는 피처가 Topic #0에 연관되는 수치 값 \n",
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb27f8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year*703.2 + 10*563.6 + game*476.3 + medical*413.2 + health*377.4 + team*346.8 + 12*343.9 + 20*340.9 + disease*332.1 + cancer*319.9 + 1993*318.3 + games*317.0 + years*306.5 + patients*299.8 + good*286.3\n",
      "Topic # 1\n",
      "don*1454.3 + just*1392.8 + like*1190.8 + know*1178.1 + people*836.9 + said*802.5 + think*799.7 + time*754.2 + ve*676.3 + didn*675.9 + right*636.3 + going*625.4 + say*620.7 + ll*583.9 + way*570.3\n",
      "Topic # 2\n",
      "image*1047.7 + file*999.1 + jpeg*799.1 + program*495.6 + gif*466.0 + images*443.7 + output*442.3 + format*442.3 + files*438.5 + color*406.3 + entry*387.6 + 00*334.8 + use*308.5 + bit*308.4 + 03*258.7\n",
      "Topic # 3\n",
      "like*620.7 + know*591.7 + don*543.7 + think*528.4 + use*514.3 + does*510.2 + just*509.1 + good*425.8 + time*417.4 + book*410.7 + read*402.9 + information*395.2 + people*393.5 + used*388.2 + post*368.4\n",
      "Topic # 4\n",
      "armenian*960.6 + israel*815.9 + armenians*699.7 + jews*690.9 + turkish*686.1 + people*653.0 + israeli*476.1 + jewish*467.0 + government*464.4 + war*417.8 + dos dos*401.1 + turkey*393.5 + arab*386.1 + armenia*346.3 + 000*345.2\n",
      "Topic # 5\n",
      "edu*1613.5 + com*841.4 + available*761.5 + graphics*708.0 + ftp*668.1 + data*517.9 + pub*508.2 + motif*460.4 + mail*453.3 + widget*447.4 + software*427.6 + mit*421.5 + information*417.3 + version*413.7 + sun*402.4\n",
      "Topic # 6\n",
      "god*2013.0 + people*721.0 + jesus*688.7 + church*663.0 + believe*563.0 + christ*553.1 + does*500.1 + christian*474.8 + say*468.6 + think*446.0 + christians*443.5 + bible*422.9 + faith*420.1 + sin*396.5 + life*371.2\n",
      "Topic # 7\n",
      "use*685.8 + dos*635.0 + thanks*596.0 + windows*548.7 + using*486.5 + window*483.1 + does*456.2 + display*389.1 + help*385.2 + like*382.8 + problem*375.7 + server*370.2 + need*366.3 + know*355.5 + run*315.3\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #', topic_index)\n",
    "        \n",
    "        #components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array 인덱스 반환\n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        #top_indexes 대상인 인덱스 별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' + '.join([str(feature_names[i])+'*'+str(round(topic[i],1)) for i in top_indexes]) \n",
    "        print(feature_concat)\n",
    "        \n",
    "#CountVectorizer 객체 내의 전체 word 명칭을 get_feature_names를 통해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "#토픽 별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52f9d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7862, 8)\n",
      "[[0.01389701 0.01394362 0.01389104 0.48221844 0.01397882 0.01389205\n",
      "  0.01393501 0.43424401]\n",
      " [0.27750436 0.18151826 0.0021208  0.53037189 0.00212129 0.00212102\n",
      "  0.00212113 0.00212125]\n",
      " [0.00544459 0.22166575 0.00544539 0.00544528 0.00544039 0.00544168\n",
      "  0.00544182 0.74567512]]\n"
     ]
    }
   ],
   "source": [
    "#lda객체의 transform()을 수행하면 개별 문서별 토픽 분포를 반환함.\n",
    "doc_topics = lda.transform(feat_vect)\n",
    "print(doc_topics.shape)\n",
    "print(doc_topics[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38113838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename 개수: 7862 filename list 10개만: ['soc.religion.christian.20630', 'sci.med.59422', 'comp.graphics.38765', 'comp.graphics.38810', 'sci.med.59449', 'comp.graphics.38461', 'comp.windows.x.66959', 'rec.motorcycles.104487', 'sci.electronics.53875', 'sci.electronics.53617']\n"
     ]
    }
   ],
   "source": [
    "#개별 문서별 토픽 분포도를 출력\n",
    "def get_filename_list(newsdata):\n",
    "    filename_list=[]\n",
    "\n",
    "    for file in newsdata.filenames:\n",
    "            #print(file)\n",
    "            filename_temp = file.split('\\\\')[-2:]\n",
    "            filename = '.'.join(filename_temp)\n",
    "            filename_list.append(filename)\n",
    "    \n",
    "    return filename_list\n",
    "\n",
    "filename_list = get_filename_list(news_df)\n",
    "print(\"filename 개수:\",len(filename_list), \"filename list 10개만:\",filename_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52894feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #0</th>\n",
       "      <th>Topic #1</th>\n",
       "      <th>Topic #2</th>\n",
       "      <th>Topic #3</th>\n",
       "      <th>Topic #4</th>\n",
       "      <th>Topic #5</th>\n",
       "      <th>Topic #6</th>\n",
       "      <th>Topic #7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian.20630</th>\n",
       "      <td>0.013897</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.482218</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.434244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59422</th>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.530372</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38765</th>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.745675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38810</th>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.578959</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.388387</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59449</th>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.408485</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.006585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x.68298</th>\n",
       "      <td>0.008935</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.157459</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.596316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian.20723</th>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.208372</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.777467</td>\n",
       "      <td>0.002361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.baseball.102656</th>\n",
       "      <td>0.357219</td>\n",
       "      <td>0.567732</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.012515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics.53606</th>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.338511</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.603767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.mideast.76505</th>\n",
       "      <td>0.062503</td>\n",
       "      <td>0.062513</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.062546</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.062520</td>\n",
       "      <td>0.562401</td>\n",
       "      <td>0.062513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7862 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic #0  Topic #1  Topic #2  Topic #3  \\\n",
       "soc.religion.christian.20630  0.013897  0.013944  0.013891  0.482218   \n",
       "sci.med.59422                 0.277504  0.181518  0.002121  0.530372   \n",
       "comp.graphics.38765           0.005445  0.221666  0.005445  0.005445   \n",
       "comp.graphics.38810           0.005439  0.005441  0.005449  0.578959   \n",
       "sci.med.59449                 0.006584  0.552000  0.006587  0.408485   \n",
       "...                                ...       ...       ...       ...   \n",
       "comp.windows.x.68298          0.008935  0.008942  0.008951  0.157459   \n",
       "soc.religion.christian.20723  0.002360  0.208372  0.002359  0.002361   \n",
       "rec.sport.baseball.102656     0.357219  0.567732  0.012504  0.012512   \n",
       "sci.electronics.53606         0.009620  0.009623  0.009621  0.338511   \n",
       "talk.politics.mideast.76505   0.062503  0.062513  0.062502  0.062546   \n",
       "\n",
       "                              Topic #4  Topic #5  Topic #6  Topic #7  \n",
       "soc.religion.christian.20630  0.013979  0.013892  0.013935  0.434244  \n",
       "sci.med.59422                 0.002121  0.002121  0.002121  0.002121  \n",
       "comp.graphics.38765           0.005440  0.005442  0.005442  0.745675  \n",
       "comp.graphics.38810           0.005440  0.388387  0.005442  0.005442  \n",
       "sci.med.59449                 0.006585  0.006585  0.006588  0.006585  \n",
       "...                                ...       ...       ...       ...  \n",
       "comp.windows.x.68298          0.008932  0.201530  0.008936  0.596316  \n",
       "soc.religion.christian.20723  0.002360  0.002359  0.777467  0.002361  \n",
       "rec.sport.baseball.102656     0.012505  0.012502  0.012511  0.012515  \n",
       "sci.electronics.53606         0.009618  0.009621  0.009619  0.603767  \n",
       "talk.politics.mideast.76505   0.062502  0.062520  0.562401  0.062513  \n",
       "\n",
       "[7862 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame으로 생성하여 문서별 토픽 분포도 확인\n",
    "import pandas as pd \n",
    "\n",
    "topic_names = ['Topic #'+ str(i) for i in range(0, 8)]\n",
    "doc_topic_df = pd.DataFrame(data=doc_topics, columns=topic_names, index=filename_list)\n",
    "doc_topic_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
