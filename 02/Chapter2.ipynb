{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passive-ordinance",
   "metadata": {},
   "source": [
    "## First ML - 붓꽃 품종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-universal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/20/0ffe8665a44bce7616bd33d4368a198fecad3b226bcafa38c63ef0f6286f/scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1MB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python375\\lib\\site-packages (from scikit-learn) (1.6.3)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/fe/8aaca2a0db7fd80f0b2cf8a16a034d3eea8102d58ff9331d2aaf1f06766a/threadpoolctl-3.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python375\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\python375\\lib\\site-packages (from scikit-learn) (1.20.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.0.2 threadpoolctl-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italian-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris               \n",
    "from sklearn.tree import DecisionTreeClassifier       \n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target 값 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris targer 명 : ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#붓꽃 데이터 셋 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "#피처(feature) 데이터 : numpy\n",
    "#피처에는 sepal length, sepal width, petal length, petal width가 있음.\n",
    "iris_data = iris.data\n",
    "\n",
    "#레이블(결정 값) 데이터 : numpy\n",
    "#label은 0(setosa), 1(versicolor), 2(virginica)로 되어있음\n",
    "iris_label = iris.target\n",
    "print('iris target 값 :', iris_label)\n",
    "print('iris targer 명 :', iris.target_names)\n",
    "\n",
    "#붓꽃 데이터 셋을 DataFrame으로\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용 데이터와 테스트용 데이터 분리 --> train_test_split()\n",
    "#test_size : 전체 데이터 세트 중 테스트 데이터 세트 비율\n",
    "#random_state : 호출할 때마다 같은 학습/테스트용 데이터 생성하기 위해 주어지는 난수 발생 값\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#의사결정 트리를 이용해 학습과 예측\n",
    "\n",
    "#DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "#학습 수행\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "#학습 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "known-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 2 0 1 0 0 1 1 1 1 2 2 0 2 1 2 2 1 0 0 1 0 0 2 1 0 1]\n",
      "[2 2 2 1 2 0 1 0 0 1 2 1 1 2 2 0 2 1 2 2 1 0 0 1 0 0 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sound-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.9333\n"
     ]
    }
   ],
   "source": [
    "#예측 성능 평가 - 정확도 측정\n",
    "#예측한 붓꽃 품종과 실제 테스트 데이터 세트의 붓꽃 품종이 얼마나 맞는지 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-occupation",
   "metadata": {},
   "source": [
    "## scikit-learn 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-myanmar",
   "metadata": {},
   "source": [
    "### 내장된 데이터 셋 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-exclusive",
   "metadata": {},
   "source": [
    "datasets.load_boston(), datasets.load_breast_cancer(), datasets.load_iris(), ...\n",
    "\n",
    "cf) fetch 계열 명령어는 데이터 크기가 커서 인터넷에서 내려받는 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "productive-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "붓꽃 데이터 세트의 키 : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "#붓꽃 데이터 세트의 구성\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))    #sklearn.utils.Bunch 클래스 - 딕셔너리와 유사\n",
    "print('붓꽃 데이터 세트의 키 :', iris_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continental-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "<class 'numpy.ndarray'>\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#feature_names: 피처의 이름\n",
    "print(type(iris_data.feature_names))\n",
    "print(len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "#target_names: 개별 레이블 이름\n",
    "print(type(iris_data.target_names))\n",
    "print(len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "#iris_data.data / iris_data['data'] - 피처들의 데이터 값\n",
    "print(type(iris_data.data))\n",
    "print(iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "#target: 분류 시 레이블 값, 회귀 시 숫자 결과값 데이터 세트\n",
    "print(type(iris_data.target))\n",
    "print(iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-importance",
   "metadata": {},
   "source": [
    "### model_selection 모듈\n",
    "\n",
    "학습 데이터와 테스트 데이터 분리 / 교차 검증 분할 및 평가 / 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "severe-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터와 테스트 데이터 분리 - train_test_split()\n",
    "\n",
    "#test_size : 전체 데이터 세트 중 테스트 데이터 세트 비율\n",
    "#train_size : 전체 데이터 세트 중 학습용 데이터 세트 비율 - 잘 사용하지 않음\n",
    "#shuffle : 데이터 섞을지 여부, 디폴트 : True\n",
    "#random_state : 호출할 때마다 같은 학습/테스트용 데이터 생성하기 위해 주어지는 난수 발생 값\n",
    "\n",
    "from sklearn.datasets import load_iris               \n",
    "from sklearn.tree import DecisionTreeClassifier       \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(\"예측 정확도:\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-gregory",
   "metadata": {},
   "source": [
    "학습 데이터 양을 일정 수준 이상으로 보장하는 것도 중요하지만, 다양한 데이터를 기반으로 예측 성능을 평가해보는 것도 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-iceland",
   "metadata": {},
   "source": [
    "### 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-pledge",
   "metadata": {},
   "source": [
    "해당 테스트 데이터에만 과적합되는 모델이 만들어져 다른 테스트용 데이터가 들어오는 경우에는 성능 저하 - 교차 검증 이용\n",
    "\n",
    "여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가 수행.(학습 데이터를 분할하여 학습 데이터와 검증 데이터로 나눔)\n",
    "\n",
    "교차 검증 기반으로 1차 평가 한 뒤에 최종적으로 테스트 데이터로 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-equipment",
   "metadata": {},
   "source": [
    "#### K 폴드 교차 검증\n",
    "\n",
    "K 개의 데이터 폴드 세트를 만들어서 K 번만큼 각 폴드 세트에 학습과 검증 평가 반복 수행, K개의 예측 평가를 평균해서 K 폴드 평가 결과로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "global-fundamental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier       \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy=[]\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expressed-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1교차 검증 정확도:1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2교차 검증 정확도:0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3교차 검증 정확도:0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4교차 검증 정확도:0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5교차 검증 정확도:0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter=0\n",
    "\n",
    "#KFold 객체의 split() 호출하면 폴드 별 학습용, 검증용 데이터의 인덱스 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter+=1\n",
    "    #반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(\"\\n#{0}교차 검증 정확도:{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-listening",
   "metadata": {},
   "source": [
    "#### Stratified K 폴드\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-story",
   "metadata": {},
   "source": [
    "불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식\n",
    "\n",
    "불균형한 분포도를 가진 레이블 : 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pacific-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris               \n",
    "\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "emerging-naples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차검증 : 1\n",
      "학습 레이블 데이터 분포\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 2\n",
      "학습 레이블 데이터 분포\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 3\n",
      "학습 레이블 데이터 분포\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print(\"##교차검증 :\", n_iter)\n",
    "    print(\"학습 레이블 데이터 분포\\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포\\n\", label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-publicity",
   "metadata": {},
   "source": [
    "3개의 폴드세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값\n",
    "\n",
    "첫번쨰 교차검증에서는 학습 레이블은 1,2 값만 추출되었고 검증 레이블은 0만 추출되어서 0을 전혀 학습하지 못하고 0을 예측하지 못한다.\n",
    "\n",
    "이런 유형으로 교차 검증 데이터 세트를 분할하면 검증 예측 정확도는 0이 될 수 밖에 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rolled-underground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차검증 : 1\n",
      "학습 레이블 데이터 분포\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 2\n",
      "학습 레이블 데이터 분포\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 3\n",
      "학습 레이블 데이터 분포\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나눈다\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print(\"##교차검증 :\", n_iter)\n",
    "    print(\"학습 레이블 데이터 분포\\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포\\n\", label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-ethernet",
   "metadata": {},
   "source": [
    "학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "leading-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2교차 검증 정확도:0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스: [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "##교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold 이용하여 학습 및 검증\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier       \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy=[]\n",
    "\n",
    "#StratifiedKFold의 split()호출 시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    #split()으로 반환된 인덱스 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    #반복 시마다 정확도 측정\n",
    "    n_iter+=1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(\"\\n#{0}교차 검증 정확도:{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}\"\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n##교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-moses",
   "metadata": {},
   "source": [
    "일반적으로 분류(Classification)에서의 교차 검증은 Stratified K 폴드로 분할되어야 한다.\n",
    "\n",
    "회귀(Regression)에서는 Stratified K 폴드가 지원되지 않는다. 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-wedding",
   "metadata": {},
   "source": [
    "#### 교차 검증을 간편하게 제공해주는 사이킷런의 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-fruit",
   "metadata": {},
   "source": [
    "cross_val_score(estimator, X, y=None, scoring=None, cv=None, ...)\n",
    "\n",
    "estimator: 분류 알고리즘 클래스인 Classifier 또는 회귀 알고리즘 클래스인 Regression 의미\n",
    "\n",
    "X: 피처 데이터 세트, y: 레이블 데이터 세트, scoring: 예측 성능 평가 지표, cv: 교차 검증 폴드 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "joint-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data=iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "#성능 지표는 정확도(accuracy), 교차 검증 세트 3개\n",
    "#cross_val_score() 수행 후 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:',np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-columbia",
   "metadata": {},
   "source": [
    "cross_val_score() API는 내부에서 Estimator을 학습, 예측, 평가시켜주므로 간단하게 교차검증 수행 가능\n",
    "\n",
    "classifier가 입력되면 Stratified K 폴드 방식으로 레이블값 분포에 따라 학습/테스트 세트 분할 - 단 하나의 평가 지표만 가능\n",
    "\n",
    "cf) cross_validate : 여러 개의 평가 지표 반환 가능, 성능 평가 지표와 수행 시간도 같이 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-seven",
   "metadata": {},
   "source": [
    "### GridSearchCV - 교차검증과 최적 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-texas",
   "metadata": {},
   "source": [
    "하이퍼 파라미터 : 머신러닝 알고리즘을 구성하는 주요 구성 요소, 이 값을 조정하여 알고리즘의 예측 성능 개선\n",
    "\n",
    "GridSearchCV API를 이용해 Classifier나 Regressor 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 적용하면서 편리하게 최적의 파라미터 도출 가능, 교차 검증 기반, (CV 값 * 파라미터 조합 개수) 만큼 학습/평가 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "appointed-prompt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#데이터를 로딩하고 학습데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "#DecisionTreeClassifier의 중요 하이퍼 파라미터인 max_depth, min_samples_split\n",
    "#파라미터를 딕셔너리 형태로 설정(하이퍼 파라미터 명칭은 문자열로, 값은 리스트로)\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
    "\n",
    "#param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "## refit=True : default, 가장 좋은 파라미터 설정으로 재학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "#학습 데이터를 cv 값만큼 폴딩 세트로 분할해 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가 수행\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "#결과는 cv_results_속성에 저장, 딕셔너리 형태로 key값과 리스트 형태의 value 값 가짐\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score',\n",
    "          'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-surge",
   "metadata": {},
   "source": [
    "params : 수행할때마다 적용된 개별 하이퍼 파라미터 값\n",
    "\n",
    "rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score 순위(1이 가장 뛰어난 순위)\n",
    "\n",
    "mean_test_score : 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가의 평균값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smooth-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최적 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최적 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incredible-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#refit=True : GridSearchCV가 최적 하이퍼 파라미터로 Estimator를 학습해 best_estimator_에 저장\n",
    "#이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "#GridSearchCV의 best_estimator_는 이미 최적 학습이 되었으므로 별도 학습 X\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-spirituality",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-piece",
   "metadata": {},
   "source": [
    "ML 알고리즘은 데이터에 기반하기 때문에 어떤 데이터를 입력으로 가지냐에 따라 결과도 달라짐.\n",
    "\n",
    "데이터에 대해 미리 처리해야할 사항\n",
    "\n",
    "1. 결손값(NaN, Null) 허용 X - 피처의 평균값 등으로 대체, 해당 피처 드롭, ...\n",
    "2. 문자열 값을 입력 값으로 허용 X - 인코딩하여 숫자형으로 변환\n",
    "   - 카테코리 형 피처 : 코드 값으로 표현\n",
    "   - 텍스트형 피처 : 피처 벡터화 등으로 벡터화, 불필요한 피처라면 삭제(단순히 데이터 로우 식별하는 식별자 피처의 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-commission",
   "metadata": {},
   "source": [
    "### 데이터 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-spectacular",
   "metadata": {},
   "source": [
    "#### 레이블 인코딩(Label encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-jumping",
   "metadata": {},
   "source": [
    "카테고리 피처를 숫자형 카테고리 값으로 변환\n",
    "\n",
    "but 숫자 변환 값이 크고 작음에 따라 순서나 중요도로 인식되는 특정 ML 알고리즘에서는 예측 성능 떨어짐\n",
    "\n",
    "선형회귀 같은 ML 알고리즘에는 적용 X, 트리 계열 ML 알고리즘 적용 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "renewable-rendering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n",
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "#LabelEncoder를 객체로 생성한 후 fit(), transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값:', labels)\n",
    "\n",
    "#문자열이 어떤 값으로 인코딩 되었는지 확인(0번부터 순서대로 변환된 인코딩 값에 대한 원본값 가짐)\n",
    "print('인코딩 클래스:', encoder.classes_)\n",
    "\n",
    "#인코딩된 값을 다시 디코딩\n",
    "print('디코딩 원본값:',encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-booth",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩(One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-texas",
   "metadata": {},
   "source": [
    "피처 값의 유형에 따라 새로운 피처를 추가해(피처 고유 값을 열 형태로 차원 변환한 뒤) 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0 표시\n",
    "\n",
    "OneHotEncoder 클래스로 변환 가능\n",
    "\n",
    "주의) 모든 문자열 값이 숫자형 값으로 변환되어야 함, 입력값으로 2차원 데이터 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elegant-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "#먼저 숫자 값으로 변환하기 위해 LabelEncoder로 변환\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "#2차원 데이터로 변환\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "#원-핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "varying-knowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_dummies() 사용하여 문자열 카테고리 값을 숫자형으로 변환할 필요 없이 바로 원-핫 인코딩\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-proposal",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "\n",
    "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
    "\n",
    "- 표준화(Standardization)\n",
    "\n",
    "데이터의 피처 각각이 평균 0, 분산 1인 가우시간 정규 분포를 가진 값으로 변환\n",
    "\n",
    "(원래 값 - 피처의 평균) / 피처의 표준편차 로 계산\n",
    "\n",
    "- 정규화(Normalization)\n",
    "\n",
    "서로 다른 피처의 크기를 통일하기 위해 크기 변환\n",
    "\n",
    "즉, 개별 데이터의 크기를 모두 똑같은 단위로 변경(최소 0 ~ 최대 1)\n",
    "\n",
    "(원래 값 - 피처의 최소값) / (피처의 최댓값 - 피처의 최솟값) 로 계산\n",
    "\n",
    "- 사이킷런 전처리에서 제공하는 Normalizer 모듈\n",
    "\n",
    "일반적인 정규화와 약간의 차이가 존재\n",
    "\n",
    "선형대수에서의 정규화 개념이 적용되었으며, 개별 벡터의 크기를 맞추기 위해 변환. 즉, 개별 벡터를 모든 피처의 벡터의 크기로 나눠줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-addiction",
   "metadata": {},
   "source": [
    "!!! 일반적 의미의 표준화와 정규화 : 피처 스케일링, 선형 대수 개념의 정규화 : 벡터 정규화 !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-channels",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    "\n",
    "피처 스케일링의 표준화 지원. 즉, 개별 피처를 평균이 0이고 분산이 1인 값으로 변환\n",
    "\n",
    "RBF 커널을 이용하는 서포트 벡터 머신, 선형회귀, 로지스틱 회귀에서 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fleet-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "#붓꽃 데이터세트 로딩하고 DataFrame으로 변환\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('feature의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "featured-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "#StandardScaler로 데이터 세트 변환\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform()시 스케일 변환된 데이터 세트가 numpy ndarray로 변환되므로 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-magazine",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "데이터 값을 0과 1 사이의 범위 값으로 변환, 음수 값 있으면 -1에서 1 값으로 변환\n",
    "\n",
    "데이터 분포가 가우시안 분포가 아닐 떄 Min, Max Scale 적용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "closed-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "#MinMaxScaler로 데이터 세트 변환\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform()시 스케일 변환된 데이터 세트가 numpy ndarray로 변환되므로 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-spirit",
   "metadata": {},
   "source": [
    "### 학습/테스트 데이터 스케일링 변환 시 유의점\n",
    "\n",
    "- fit() : 데이터 변환을 위한 기준 정보 설정\n",
    "\n",
    "- transform() : 설정된 정보를 이용해 데이터 변환\n",
    "\n",
    "- fit_transform() : fit, transform 한번에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-journalism",
   "metadata": {},
   "source": [
    "학습 데이터에 fit(), transform() 적용하면 테스트 데이터에는 다시 fit()을 수행하지 않고 학습 데이터에 fit()을 수행한 결과를 이용해 transform()을 적용\n",
    "\n",
    "즉, 학습 데이터로 fit()이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용, 그렇지 않으면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 달라짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "annoying-mouth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터:  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scaled된 train_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터:  [0 1 2 3 4 5]\n",
      "Scaled된 test_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "#Scaler 클래스의 fit, transform은 2차원 이상 데이터만 가능\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터: ', np.round(train_array.reshape(-1), 2))\n",
    "print('Scaled된 train_array 데이터: ', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "#test_array에 Scale변환 할 때는 반드시 fit()호출하지 않고 transform()만으로 변환해야 함\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터: ', np.round(test_array.reshape(-1), 2))\n",
    "print('Scaled된 test_array 데이터: ', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-palestine",
   "metadata": {},
   "source": [
    "1. 전체 데이터의 스케일링 변환 적용한 뒤 학습과 테스트 데이터 분리\n",
    "\n",
    "2. 1이 여의치 않으면 테스트 데이터 변환 시에는 fit(), fit_transform() 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체 이용해 transform()으로 변환\n",
    "\n",
    "PCA와 같은 차원 축소 변환이나 텍스트의 피처 벡터화 변환 작업 시에도 동일하게 적용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
